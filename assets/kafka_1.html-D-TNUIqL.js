import{_ as a,c as n,e,o as l}from"./app-C7ucYrat.js";const i="/blog/kafka.assets/image-20210531093311879.png",t="/blog/kafka.assets/image-20210523183408179.png",p="/blog/kafka.assets/image-20210523184704038.png",c="/blog/kafka.assets/image-20210609214557490.png",o="/blog/kafka.assets/image-20210609214455036.png",r="/blog/kafka.assets/image-20210609214824009.png",d="/blog/kafka.assets/image-20210608094154665.png",k="/blog/kafka.assets/image-20210608094230053.png",m="/blog/kafka.assets/image-20210608095811782.png",u={};function v(b,s){return l(),n("div",null,s[0]||(s[0]=[e(`<h2 id="kafka简介" tabindex="-1"><a class="header-anchor" href="#kafka简介"><span>Kafka简介：</span></a></h2><p>Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。</p><h2 id="安装维护" tabindex="-1"><a class="header-anchor" href="#安装维护"><span>安装维护</span></a></h2><h3 id="命令操作" tabindex="-1"><a class="header-anchor" href="#命令操作"><span>命令操作</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment"># zk 安装</span></span>
<span class="line"><span class="token function">wget</span> https://mirror.bit.edu.cn/apache/zookeeper/zookeeper‐3.5.8/apache‐zookeeper‐3.5.8‐bin.tar.gz </span>
<span class="line"><span class="token function">tar</span> ‐zxvf apache‐zookeeper‐3.5.8‐bin.tar.gz</span>
<span class="line"><span class="token builtin class-name">cd</span> apache‐zookeeper‐3.5.8‐bin </span>
<span class="line"><span class="token function">cp</span> conf/zoo_sample.cfg conf/zoo.cfg </span>
<span class="line"><span class="token comment"># 启动zookeeper </span></span>
<span class="line">bin/zkServer.sh start </span>
<span class="line">bin/zkCli.sh </span>
<span class="line"><span class="token comment">#查看zk的根目录相关节点</span></span>
<span class="line"><span class="token function">ls</span> / </span>
<span class="line"></span>
<span class="line"><span class="token comment"># kafka 安装</span></span>
<span class="line"><span class="token comment"># 2.11是scala的版本，2.4.1是kafka的版本 </span></span>
<span class="line"><span class="token function">wget</span> https://mirror.bit.edu.cn/apache/kafka/2.4.1/kafka_2.11‐2.4.1.tgz </span>
<span class="line"><span class="token function">tar</span> ‐xzf kafka_2.11‐2.4.1.tgz </span>
<span class="line"><span class="token builtin class-name">cd</span> kafka_2.11‐2.4.1</span>
<span class="line"><span class="token comment">#broker.id属性在kafka集群中必须要是唯一 </span></span>
<span class="line"><span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">0</span> </span>
<span class="line"><span class="token comment">#kafka部署的机器ip和提供服务的端口号</span></span>
<span class="line"><span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://localhost:9092 </span>
<span class="line"><span class="token comment">#kafka的消息存储文件 </span></span>
<span class="line"><span class="token assign-left variable">log.dir</span><span class="token operator">=</span>/usr/local/data/kafka‐logs </span>
<span class="line"><span class="token comment">#kafka连接zookeeper的地址 </span></span>
<span class="line"><span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span>localhost:2181</span>
<span class="line"><span class="token comment"># 启动kafka，运行日志在logs目录的server.log文件里 </span></span>
<span class="line">bin/kafka‐server‐start.sh ‐daemon config/server.properties </span>
<span class="line"><span class="token comment">#后台启动，不会打印日志到控制台 3 或者用 </span></span>
<span class="line">bin/kafka‐server‐start.sh config/server.properties <span class="token operator">&amp;</span> </span>
<span class="line"><span class="token comment"># 我们进入zookeeper目录通过zookeeper客户端查看下zookeeper的目录树 </span></span>
<span class="line">bin/zkCli.sh </span>
<span class="line"><span class="token function">ls</span> / <span class="token comment">#查看zk的根目录kafka相关节点 </span></span>
<span class="line"><span class="token function">ls</span> /brokers/ids <span class="token comment">#查看kafka节点 </span></span>
<span class="line"><span class="token comment"># 停止kafka </span></span>
<span class="line">bin/kafka‐server‐stop.sh</span>
<span class="line"><span class="token comment">#创建名为 test 的 topic,通过手工的方式创建Topic，当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建</span></span>
<span class="line"><span class="token comment">#partitions 分区数</span></span>
<span class="line"><span class="token comment">#replication-factor 副本数</span></span>
<span class="line">bin/kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--zookeeper</span> localhost:2181 --replication-factor <span class="token number">3</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> <span class="token parameter variable">--topic</span> topic_test2</span>
<span class="line"><span class="token comment">#查看kafka中目前存在的topic</span></span>
<span class="line">bin/kafka-topics.sh <span class="token parameter variable">--list</span> <span class="token parameter variable">--zookeeper</span> localhost:2181</span>
<span class="line"><span class="token comment">#删除主题</span></span>
<span class="line">bin/kafka-topics.sh <span class="token parameter variable">--delete</span> <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> <span class="token parameter variable">--zookeeper</span> localhost:2181</span>
<span class="line"><span class="token comment">#发送消息,每行都是一条消息</span></span>
<span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> </span>
<span class="line"><span class="token operator">&gt;</span>this is a msg</span>
<span class="line"><span class="token operator">&gt;</span>this is a another msg </span>
<span class="line"><span class="token comment">#消费消息</span></span>
<span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span></span>
<span class="line"><span class="token comment">#如果想要消费之前的消息可以通过--from-beginning参数指定，如下命令：</span></span>
<span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 </span>
<span class="line"><span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> </span>
<span class="line"><span class="token comment">#消费多主题</span></span>
<span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--whitelist</span> <span class="token string">&quot;test|test-2&quot;</span></span>
<span class="line"><span class="token comment">#单播消费,一条消息只能被某一个消费者消费的模式，类似queue模式，只需让所有消费者在同一个消费组里即可</span></span>
<span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092  --consumer-property <span class="token assign-left variable">group.id</span><span class="token operator">=</span>testGroup <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span></span>
<span class="line"><span class="token comment">#多播消费 发布订阅模式，指定到不同的消费组中</span></span>
<span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --consumer-property <span class="token assign-left variable">group.id</span><span class="token operator">=</span>testGroup-2 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span></span>
<span class="line"><span class="token comment">#查看消费组名称</span></span>
<span class="line">bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--list</span> </span>
<span class="line"><span class="token comment">#查看消费组的消费偏移量</span></span>
<span class="line"><span class="token comment">#current-offset：当前消费组的已消费偏移量</span></span>
<span class="line"><span class="token comment">#log-end-offset：主题对应分区消息的结束偏移量(HW)</span></span>
<span class="line"><span class="token comment">#lag：当前消费组未消费的消息数</span></span>
<span class="line">bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--group</span> testGroup-2</span>
<span class="line"><span class="token comment">#增加 partitions 数量</span></span>
<span class="line">bin/kafka-topics.sh <span class="token parameter variable">-alter</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> <span class="token parameter variable">--zookeeper</span> localhost:2181 <span class="token parameter variable">--topic</span> test5</span>
<span class="line"><span class="token comment">#查看 topic 状态</span></span>
<span class="line">bin/kafka-topics.sh <span class="token parameter variable">--describe</span> <span class="token parameter variable">--zookeeper</span> <span class="token number">172.23</span>.4.32:2181/kafka/product/kafka821 <span class="token parameter variable">--topic</span> topic_test2</span>
<span class="line"></span>
<span class="line"><span class="token comment">#临时设置日志存储时间</span></span>
<span class="line">bin/kafka-configs.sh  <span class="token parameter variable">--zookeeper</span> <span class="token number">172.23</span>.4.32:2181/kafka/product/kafka821 <span class="token parameter variable">--alter</span> --add-config <span class="token string">&#39;retention.ms=4320000&#39;</span> --entity-name topic_tset2 --entity-type topics</span>
<span class="line"><span class="token comment">#删除设置</span></span>
<span class="line">bin/kafka-configs.sh  <span class="token parameter variable">--zookeeper</span> <span class="token number">172.23</span>.4.32:2181/kafka/product/kafka821 <span class="token parameter variable">--alter</span> --delete-config <span class="token string">&#39;retention.ms&#39;</span> --entity-name topic_tset2 --entity-type topics</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 如果是java客户端，查看消费offset偏移量时，需要带上 --new-consumer 参数</span></span>
<span class="line">bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server <span class="token number">172.23</span>.4.32:9092,172.23.4.33:9092,172.23.4.33:9093 <span class="token parameter variable">--group</span> nike_callback_consumer3 <span class="token parameter variable">--describe</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="组件介绍" tabindex="-1"><a class="header-anchor" href="#组件介绍"><span>组件介绍</span></a></h2><p><img src="`+i+`" alt="image-20210531093311879"></p><table><thead><tr><th><strong>名称</strong></th><th><strong>解释</strong></th></tr></thead><tbody><tr><td>Broker</td><td>消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群</td></tr><tr><td>Topic</td><td>Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic</td></tr><tr><td>Producer</td><td>消息生产者，向Broker发送消息的客户端</td></tr><tr><td>Consumer</td><td>消息消费者，从Broker读取消息的客户端</td></tr><tr><td>ConsumerGroup</td><td>每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息</td></tr><tr><td>Partition</td><td>物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的</td></tr></tbody></table><h3 id="server-properties-主要配置" tabindex="-1"><a class="header-anchor" href="#server-properties-主要配置"><span>server.properties 主要配置</span></a></h3><div class="language-http line-numbers-mode" data-highlighter="prismjs" data-ext="http" data-title="http"><pre class="language-http"><code><span class="line">#配置文档地址</span>
<span class="line"><span class="token header"><span class="token header-name keyword">http</span><span class="token punctuation">:</span><span class="token header-value">//kafka.apache.org/documentation/#brokerconfigs</span></span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><table><thead><tr><th><strong>Property</strong></th><th><strong>Default</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>broker.id</td><td>0</td><td>每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的<code>名字</code>，你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。</td></tr><tr><td>log.dirs</td><td>/tmp/kafka-logs</td><td>kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。</td></tr><tr><td>listeners</td><td>PLAINTEXT://localhost:9092</td><td>server接受客户端连接的端口，ip配置kafka本机ip即可</td></tr><tr><td>zookeeper.connect</td><td>localhost:2181</td><td>zooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3</td></tr><tr><td>log.retention.hours</td><td>168</td><td>每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。</td></tr><tr><td>num.partitions</td><td>1</td><td>创建topic的默认分区数</td></tr><tr><td>default.replication.factor</td><td>1</td><td>自动创建topic的默认副本数量，建议设置为大于等于2</td></tr><tr><td>min.insync.replicas</td><td>1</td><td>当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常</td></tr></tbody></table><h2 id="使用" tabindex="-1"><a class="header-anchor" href="#使用"><span>使用：</span></a></h2><h3 id="controller" tabindex="-1"><a class="header-anchor" href="#controller"><span>Controller</span></a></h3><blockquote><p>在Kafka早期版本，对于分区和副本的状态的管理依赖于zookeeper的Watcher和队列：每一个broker都会在zookeeper注册Watcher，所以zookeeper就会出现大量的Watcher, 假设某个broker宕机，且此broker上的partition很多比较多，会造成多个Watcher触发，造成集群内大规模调整；每一个replica都要去再次zookeeper上注册监视器，当集群规模很大的时候，zookeeper负担很重。这种设计很容易出现脑裂和羊群效应以及zookeeper集群过载</p></blockquote><p>在<code>kafka</code>集群中，会有一个或多个<code>broker</code>，其中一个<code>broker</code>被选为<code>控制器(Controller)</code>，主要职责：</p><ul><li><code>partition leader</code> 选举</li><li>主题管理（创建、删除、增加分区） <ul><li>这里的主题管理，就是指控制器帮助我们完成对 Kafka，主题的创建、删除以及分区增加的操作；</li></ul></li><li>分区重分配 <ul><li>当某个<code>Topic</code>增加分区时，负责新分区 被其他<code>broker</code>感知到</li></ul></li><li>集群成员管理 <ul><li>自动检测新增 Broker、Broker 主动关闭及被动宕机，监听<code>/brokers/ids</code>子节点的数据变更</li></ul></li><li>数据服务 <ul><li>向其他 Broker 提供数据服务</li><li>所有主题信息。包括具体的分区信息，比如领导者副本是谁，ISR 集合中有哪些副本等。</li><li>所有 Broker 信息。包括当前都有哪些运行中的 Broker，哪些正在关闭中的 Broker 等。</li><li>所有涉及运维任务的分区。包括当前正在进行<code>leader</code>选举以及分区重分配的分区列表。</li><li>值得注意的是，这些数据其实在 ZooKeeper 中也保存了一份。每当控制器初始化时，它都会从 ZooKeeper 上读取对应的元数据并填充到自己的缓存中。有了这些数据，控制器就能对外提供数据服务了。这里的对外主要是指对其他 Broker 而言，控制器通过向这些 Broker 发送请求的方式将这些数据同步到其他 Broker 上</li></ul></li></ul><h4 id="controller选举机制" tabindex="-1"><a class="header-anchor" href="#controller选举机制"><span>Controller选举机制</span></a></h4><ul><li><p>每个<code>broker</code>会尝试在zk创建<code>/controller</code> <code>临时</code>节点，谁创建成功，就会成为集群的总控制器<code>controller</code></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token punctuation">{</span><span class="token string">&quot;version&quot;</span>:1,<span class="token string">&quot;brokerid&quot;</span>:0,<span class="token string">&quot;timestamp&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;1622977268033&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p>集群中的其他<code>broker</code>都会一直监听<code>/controller</code>，如果<code>controller</code>所在的broker宕机，临时节点消失，则会竞争再次创建<code>/controller</code>临时节点，选举出新的<code>controller</code></p></li><li><p>每个<code>broker</code>内存中还会记录有<code>activeControllerId</code>,如果某个broker之前是<code>ctonrller</code>,由于网络等原因，导致集群中的<code>controller</code>重新选举，网络恢复后，获取到<code>/controler</code>节点中记录的和自身<code>brokerId</code>不同，则会进行<code>退位</code>操作,比如关闭相应资源，关闭一些zk监听节点等</p></li><li><p>可以通过手动删除zk下<code>/controller</code>节点，来触发<code>Controller</code>的选举</p></li></ul><h4 id="controller唯一性" tabindex="-1"><a class="header-anchor" href="#controller唯一性"><span>Controller唯一性</span></a></h4><ul><li><code>controller_epoch</code>:用于记录<code>controller</code>的变更次数，保存在zk<code>/controller_epoch</code>中，初始值为1，控制器发生变更时，此值增加1，也称作<code>控制器的纪元</code></li><li><code>broker</code>会存储最新<code>/controller_epoch</code>的值，控制器的每次交互，都会携带上<code>controller_epoch</code>这个字段，收到<code>controller</code>的命令之后，会拿到<code>controller_epoch</code>进行比较，如果小于内存中的<code>controller_epoch</code>，则忽略此命令</li></ul><h3 id="topic和partition" tabindex="-1"><a class="header-anchor" href="#topic和partition"><span>Topic和partition</span></a></h3><h4 id="概念" tabindex="-1"><a class="header-anchor" href="#概念"><span>概念：</span></a></h4><p>可以理解Topic是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件:</p><p>Partition是一个有序的message序列，这些message按顺序添加到一个叫做commit log的文件中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message。 每个partition，都对应一个commit log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的。</p><p>每个partition，存在1个<code>leader</code> , 0个或多个<code>followers</code>,<strong>leader处理所有的针对这个partition的读写请求，followers被动复制leader的结果，不提供读写，如果某个leader宕机，其中的一个follower将会自动变成新的leader</strong>。可以看到每个<code>partition</code>的<code>leader</code>及<code>follower</code>，均匀的分布在不同的<code>broker</code>,且一个<code>broker</code>不可能出现某个<code>partition</code>的多个副本</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment">#查看 topic 状态</span></span>
<span class="line">bin/kafka-topics.sh <span class="token parameter variable">--describe</span> <span class="token parameter variable">--zookeeper</span> localhost:2181 <span class="token parameter variable">--topic</span> topic_test2</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="`+t+'" alt="image-20210523183408179"></p><ul><li>leader节点负责给定partition的所有读写请求</li><li>replicas 表示某个partition在哪几个broker上存在备份。不管这个几点是不是<code>leader</code>，甚至这个节点挂了，也会列出。</li><li>isr 是replicas的一个子集，它只列出当前还存活着的，并且<strong>已同步备份</strong>了该partition的节点。 <ul><li>节点必须能够维护与ZooKeeper的会话(通过ZooKeeper的心跳机制)</li><li>副本能复制leader上的所有写操作，并且不能落后太多 <ul><li>与leader副本同步滞后的副本，是由 <code>replica.lag.time.max.ms</code> 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表</li></ul></li></ul></li></ul><blockquote><p>当kill broker.id =0 的节点之后，再查看 topic的信息：</p><p><img src="'+p+'" alt="image-20210523184704038"></p></blockquote><h4 id="leader选举机制" tabindex="-1"><a class="header-anchor" href="#leader选举机制"><span>Leader选举机制</span></a></h4><ul><li><code>controller</code>是什么?</li><li><code>controller</code>感知到分区<code>leader</code>所在的<code>broker</code>挂了(controller 通过监听zk节点)</li><li><code>unclean.leader.election.enable=false</code>，<code>controller</code>会根据<code>AR</code>集合的顺序，并且在<code>ISR</code>列表中存活的作为<code>leader</code>「优先副本」 <ul><li>优先副本：replicas 中的第一个</li></ul></li><li>如果参数<code>unclean.leader.election.enable=true</code>，则可以在<code>ISR</code>以外的列表中选择<code>leader</code>,这种可以提高可用性，但是选择的<code>leader</code>可能数据缺失比较多</li></ul><h4 id="分区自动平衡" tabindex="-1"><a class="header-anchor" href="#分区自动平衡"><span>分区自动平衡</span></a></h4><blockquote><p><code>broker</code> 自平衡</p></blockquote><p><strong>执行下面步骤</strong></p><ul><li>kill <code>broker2</code>，此时<code>partition0</code>、<code>partition1</code> 的 leader都在broker0</li></ul><p><img src="'+c+'" alt="image-20210609214557490"></p><ul><li>启动<code>broker2</code>，刚启动时，<code>partition0</code>、<code>partition1</code> 的 leader都在broker0</li></ul><p><img src="'+o+'" alt="image-20210609214455036"></p><ul><li>注意：此时 broker0 的平衡率= <code>非优先副本的leader个数(partition0)</code> /<code>总分区数(3)</code> =33.33%,大于默认的10%</li><li>五分钟后：partition0, leader 重新选举为 broker2</li></ul><p><img src="'+r+`" alt="image-20210609214824009"></p><blockquote><p>通过上面现象可知：分区自平衡，是自动帮助broker均衡压力的一种机制</p><p>注意：生产环境建议关闭自动平衡，因为自平衡过程中，势必造成业务阻塞，频繁超时情况，所以建议手动平衡</p></blockquote><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre class="language-properties"><code><span class="line"><span class="token comment">#是否开启自动平衡</span></span>
<span class="line"><span class="token key attr-name">auto.leader.rebalance.enabl</span><span class="token punctuation">:</span><span class="token value attr-value">true</span></span>
<span class="line"><span class="token comment">#broker中的不平衡率 = 非优先副本的leader个数 / 分区总数</span></span>
<span class="line"><span class="token comment">#优先副本：replicas 中的第一个</span></span>
<span class="line"><span class="token comment">#不平衡率 &gt; 此配置(%)，则需要出发自动平衡策略，将优先副本设置为leader</span></span>
<span class="line"><span class="token key attr-name">leader.imbalance.per.broker.percentage</span><span class="token punctuation">=</span><span class="token value attr-value">10</span></span>
<span class="line"><span class="token comment">#执行周期 300s,五分钟</span></span>
<span class="line"><span class="token key attr-name">leader.imbalance.check.interval.seconds</span><span class="token punctuation">=</span><span class="token value attr-value">300</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">#手动执行</span></span>
<span class="line"><span class="token key attr-name">bin/kafka-preferred-replica-election.sh</span> <span class="token value attr-value">--zookeeper localhost:2181</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="如何选择合适的分区数" tabindex="-1"><a class="header-anchor" href="#如何选择合适的分区数"><span>如何选择合适的分区数？</span></a></h4><h5 id="性能测试工具" tabindex="-1"><a class="header-anchor" href="#性能测试工具"><span>性能测试工具</span></a></h5><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment"># num-records 数据条数</span></span>
<span class="line"><span class="token comment"># record-size 每条数据大小</span></span>
<span class="line"><span class="token comment"># throughput 小于0，表示不限速，大于0，每秒限速(kb/s)</span></span>
<span class="line"><span class="token comment"># acks 0直接返回，1 leader持久化后返回，-1 或 all 所有副本持久化后返回</span></span>
<span class="line"><span class="token comment"># print-metrics 额外打印一些指标信息</span></span>
<span class="line">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> topic_test --num-records <span class="token number">1000</span> --record-size <span class="token number">1024</span> <span class="token parameter variable">--throughput</span> <span class="token parameter variable">-1</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>localhost:9092 <span class="token assign-left variable">acks</span><span class="token operator">=</span><span class="token number">1</span> --print-metrics</span>
<span class="line"></span>
<span class="line"><span class="token comment"># records/sec 每秒发送的数据条数</span></span>
<span class="line"><span class="token comment"># MB/sec 每秒发送大小</span></span>
<span class="line"><span class="token comment"># avg latency 每条消息处理平均时长</span></span>
<span class="line"><span class="token comment"># max latency 每条消息处理最大时长</span></span>
<span class="line"><span class="token comment"># 10 ms 50th, 15 ms 95th, 15 ms 99th, 134 ms 99.9th，表示 50%、95% 等消息处理时长</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><img src="`+d+'" alt="image-20210608094154665" style="zoom:150%;"><p>当设置 <code>throughput 100 时</code></p><img src="'+k+'" alt="image-20210608094230053" style="zoom:150%;"><h5 id="分区数越多吞吐量越高吗" tabindex="-1"><a class="header-anchor" href="#分区数越多吞吐量越高吗"><span>分区数越多吞吐量越高吗?</span></a></h5><ul><li><p>首先分别创建分区数为 20、50、100、200、500、1000 topic，对应 主题名称分别为 topic-1、topic 20、topic-50、topic-100、topic-200、topic-500、topic-1000 ，所有主题的副本因子都设置为 0</p></li><li><p>每个topic都发送 1000000条，size=1024的数据，结果如下：</p><img src="'+m+`" alt="image-20210608095811782"></li></ul><blockquote><p>注意：此结果比较片面，跟硬件环境有一定关系，只是能说明一种现象，并非随着分区数增加，吞吐量一直增加</p></blockquote><h5 id="分区数如何设置" tabindex="-1"><a class="header-anchor" href="#分区数如何设置"><span>分区数如何设置</span></a></h5><blockquote><p>最好的答案是：视具体情况而定</p><p>如上述实验，合适的分区数增加，能够在一定程度上提高吞吐量，但是超过一定阈值后，不升反降，所以如果对吞吐量有一定要求，最好的方案是：投入生产环境之前，模拟线上硬件环境、数据量，做一个完整的吞吐量测试，以找到合适的分区数阈值，同时尽量设置分区数为集群内broker节点的倍数；如 3个broker，可以设定分区数3、6、9等，倍数的选定，可以参考预估的吞吐量。但是broker数量很多的几十上百，则这种方式也不适用，进一步考虑基础架构的参考因素</p><p>分区数上限：受到系统文件描述符限制</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment">#软限制</span></span>
<span class="line"><span class="token builtin class-name">ulimit</span> <span class="token parameter variable">-Sn</span></span>
<span class="line"><span class="token comment">#硬限制</span></span>
<span class="line"><span class="token builtin class-name">ulimit</span> <span class="token parameter variable">-Hn</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote><h4 id="为什么要对topic下数据进行分区存储" tabindex="-1"><a class="header-anchor" href="#为什么要对topic下数据进行分区存储"><span><strong>为什么要对Topic下数据进行分区存储？</strong></span></a></h4><ul><li>commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据。</li><li>提高可用性</li><li>提高并行度</li></ul><h3 id="日志存储" tabindex="-1"><a class="header-anchor" href="#日志存储"><span>日志存储</span></a></h3><h4 id="文件目录布局" tabindex="-1"><a class="header-anchor" href="#文件目录布局"><span>文件目录布局</span></a></h4><p>kafka会根据配置的日志保留时间(<code>log.retention.hours</code>)确认消息多久被删除，默认保留最近一周的日志消息</p><p>一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old segment file快速被删除，kafka规定了一个段位的 log 文件最大为 1G，做这个限制目的是为了方便把 log 文件加载到内存去操作：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment"># 文件名称表示当前文件offset的开始值</span></span>
<span class="line"><span class="token comment"># 部分消息的offset索引文件，kafka每次往分区发4K(log.index.interval.bytes)消息就会记录一条当前消息的offset到index文件</span></span>
<span class="line"><span class="token comment"># 如果要定位消息的offset会先在这个文件里快速定位，再去log文件里找具体消息</span></span>
<span class="line">00000000000000000000.index</span>
<span class="line"><span class="token comment"># 消息存储文件，主要存offset和消息体</span></span>
<span class="line">00000000000000000000.log</span>
<span class="line"><span class="token comment"># 消息的发送时间索引文件，kafka每次往分区发4K(log.index.interval.bytes)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，</span></span>
<span class="line"><span class="token comment"># 如果需要按照时间来定位消息的offset，会先在这个文件里查找</span></span>
<span class="line">00000000000000000000.timeindex</span>
<span class="line">00000000000005367851.index</span>
<span class="line">00000000000005367851.log</span>
<span class="line">00000000000005367851.timeindex</span>
<span class="line"></span>
<span class="line">00000000000009936472.index</span>
<span class="line">00000000000009936472.log</span>
<span class="line">00000000000009936472.timeindex</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们知道consumer提交的offset是保存在内部topic<code>_consumer_offset</code>中，初始情况下，这个主题并不存在，当第一次有消费者消费消息时，会自动创建这个主题</p><h4 id="消息压缩" tabindex="-1"><a class="header-anchor" href="#消息压缩"><span>消息压缩</span></a></h4><h3 id="zookeeper存储" tabindex="-1"><a class="header-anchor" href="#zookeeper存储"><span>Zookeeper存储</span></a></h3><p><img src="https://note.youdao.com/yws/public/resource/d9fed88c81ff75e6c0e6364012d19fef/xmlnote/2F76FF53FBF643E785B18CD0F0C2D3D2/83219" alt="img"></p><h2 id="扩展" tabindex="-1"><a class="header-anchor" href="#扩展"><span>扩展</span></a></h2><h3 id="efak" tabindex="-1"><a class="header-anchor" href="#efak"><span>EFAK</span></a></h3><blockquote><p>参考：https://www.cnblogs.com/smartloli/p/9371904.html</p><p>下载：http://download.smartloli.org/</p><p>配置环境变量：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token builtin class-name">export</span> <span class="token assign-left variable">KE_HOME</span><span class="token operator">=</span>/home/hadoop/kafka/kafka-eagle-bin-2.0.8/efak-web-2.0.8</span>
<span class="line"><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$KE_HOME</span>/bin</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>修改配置文件</p><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre class="language-properties"><code><span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># multi zookeeper &amp; kafka cluster list</span></span>
<span class="line"><span class="token comment"># Settings prefixed with &#39;kafka.eagle.&#39; will be deprecated, use &#39;efak.&#39; instead</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">efak.zk.cluster.alias</span><span class="token punctuation">=</span><span class="token value attr-value">cluster1</span></span>
<span class="line"><span class="token key attr-name">cluster1.zk.list</span><span class="token punctuation">=</span><span class="token value attr-value">172.20.39.2:2181/kafka/product/kafka281</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># zookeeper enable acl</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment">#cluster1.zk.acl.enable=false</span></span>
<span class="line"><span class="token comment">#cluster1.zk.acl.schema=digest</span></span>
<span class="line"><span class="token comment">#cluster1.zk.acl.username=test</span></span>
<span class="line"><span class="token comment">#cluster1.zk.acl.password=test123</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># broker size online list</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.broker.size</span><span class="token punctuation">=</span><span class="token value attr-value">20</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># zk client thread limit</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">kafka.zk.limit.size</span><span class="token punctuation">=</span><span class="token value attr-value">32</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># EFAK webui port</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">efak.webui.port</span><span class="token punctuation">=</span><span class="token value attr-value">8048</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka jmx acl and ssl authenticate</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.acl</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.user</span><span class="token punctuation">=</span><span class="token value attr-value">keadmin</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.password</span><span class="token punctuation">=</span><span class="token value attr-value">keadmin123</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.ssl</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.truststore.location</span><span class="token punctuation">=</span><span class="token value attr-value">/data/ssl/certificates/kafka.truststore</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.truststore.password</span><span class="token punctuation">=</span><span class="token value attr-value">ke123456</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka offset storage</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.offset.storage</span><span class="token punctuation">=</span><span class="token value attr-value">kafka</span></span>
<span class="line"><span class="token comment">#cluster2.efak.offset.storage=zk</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.jmx.uri</span><span class="token punctuation">=</span><span class="token value attr-value">service:jmx:rmi:///jndi/rmi://%s/jmxrmi</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka metrics, 15 days by default</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">efak.metrics.charts</span><span class="token punctuation">=</span><span class="token value attr-value">true</span></span>
<span class="line"><span class="token key attr-name">efak.metrics.retain</span><span class="token punctuation">=</span><span class="token value attr-value">15</span></span>
<span class="line"><span class="token comment"># kafka sql topic records max</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">efak.sql.topic.records.max</span><span class="token punctuation">=</span><span class="token value attr-value">5000</span></span>
<span class="line"><span class="token key attr-name">efak.sql.topic.preview.records.max</span><span class="token punctuation">=</span><span class="token value attr-value">10</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># delete kafka topic token</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">efak.topic.token</span><span class="token punctuation">=</span><span class="token value attr-value">keadmin</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka sasl authenticate</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.sasl.enable</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.sasl.protocol</span><span class="token punctuation">=</span><span class="token value attr-value">SASL_PLAINTEXT</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.sasl.mechanism</span><span class="token punctuation">=</span><span class="token value attr-value">SCRAM-SHA-256</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.sasl.client.id</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.blacklist.topics</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.sasl.cgroup.enable</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster1.efak.sasl.cgroup.topics</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.sasl.enable</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.sasl.protocol</span><span class="token punctuation">=</span><span class="token value attr-value">SASL_PLAINTEXT</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.sasl.mechanism</span><span class="token punctuation">=</span><span class="token value attr-value">PLAIN</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.sasl.client.id</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.blacklist.topics</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.sasl.cgroup.enable</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster2.efak.sasl.cgroup.topics</span><span class="token punctuation">=</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka ssl authenticate</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.enable</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.protocol</span><span class="token punctuation">=</span><span class="token value attr-value">SSL</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.truststore.location</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.truststore.password</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.keystore.location</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.keystore.password</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.key.password</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.endpoint.identification.algorithm</span><span class="token punctuation">=</span><span class="token value attr-value">https</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.blacklist.topics</span><span class="token punctuation">=</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.cgroup.enable</span><span class="token punctuation">=</span><span class="token value attr-value">false</span></span>
<span class="line"><span class="token key attr-name">cluster3.efak.ssl.cgroup.topics</span><span class="token punctuation">=</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka sqlite jdbc driver address</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment">#efak.driver=org.sqlite.JDBC</span></span>
<span class="line"><span class="token comment">#efak.url=jdbc:sqlite:/hadoop/kafka-eagle/db/ke.db</span></span>
<span class="line"><span class="token comment">#efak.username=root</span></span>
<span class="line"><span class="token comment">#efak.password=www.kafka-eagle.org</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token comment"># kafka mysql jdbc driver address</span></span>
<span class="line"><span class="token comment">######################################</span></span>
<span class="line"><span class="token key attr-name">efak.driver</span><span class="token punctuation">=</span><span class="token value attr-value">com.mysql.cj.jdbc.Driver</span></span>
<span class="line"><span class="token key attr-name">efak.url</span><span class="token punctuation">=</span><span class="token value attr-value">jdbc:mysql://172.20.48.2:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span></span>
<span class="line"><span class="token key attr-name">efak.username</span><span class="token punctuation">=</span><span class="token value attr-value">appcpa</span></span>
<span class="line"><span class="token key attr-name">efak.password</span><span class="token punctuation">=</span><span class="token value attr-value">appcpa</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>启动：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line">ke.sh start    </span>
<span class="line">ke.sh stop    </span>
<span class="line">ke.sh restart    </span>
<span class="line">ke.sh status    </span>
<span class="line">ke.sh stats    </span>
<span class="line">ke.sh <span class="token function">find</span> <span class="token punctuation">[</span>ClassName<span class="token punctuation">]</span>    </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote>`,67)]))}const f=a(u,[["render",v],["__file","kafka_1.html.vue"]]),g=JSON.parse('{"path":"/blogs/jishu/kakfa/kafka_1.html","title":"Kafka 入门","lang":"en-US","frontmatter":{"title":"Kafka 入门","date":"2021-05-02T00:00:00.000Z","author":"shuiMu","categories":["技术"],"tags":["kafka"]},"headers":[{"level":2,"title":"Kafka简介：","slug":"kafka简介","link":"#kafka简介","children":[]},{"level":2,"title":"安装维护","slug":"安装维护","link":"#安装维护","children":[{"level":3,"title":"命令操作","slug":"命令操作","link":"#命令操作","children":[]}]},{"level":2,"title":"组件介绍","slug":"组件介绍","link":"#组件介绍","children":[{"level":3,"title":"server.properties 主要配置","slug":"server-properties-主要配置","link":"#server-properties-主要配置","children":[]}]},{"level":2,"title":"使用：","slug":"使用","link":"#使用","children":[{"level":3,"title":"Controller","slug":"controller","link":"#controller","children":[]},{"level":3,"title":"Topic和partition","slug":"topic和partition","link":"#topic和partition","children":[]},{"level":3,"title":"日志存储","slug":"日志存储","link":"#日志存储","children":[]},{"level":3,"title":"Zookeeper存储","slug":"zookeeper存储","link":"#zookeeper存储","children":[]}]},{"level":2,"title":"扩展","slug":"扩展","link":"#扩展","children":[{"level":3,"title":"EFAK","slug":"efak","link":"#efak","children":[]}]}],"git":{"createdTime":1729235013000,"updatedTime":1729235013000,"contributors":[{"name":"peng.li","email":"lip.app@qq.com","commits":1}]},"filePathRelative":"blogs/技术/kakfa/kafka_1.md"}');export{f as comp,g as data};
